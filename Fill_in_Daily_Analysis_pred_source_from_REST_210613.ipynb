{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fill in Daily Analysis pred - source from REST - 210613.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNirLcJ11Z55IaAdsboPdaa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spoer13/jambu/blob/master/Fill_in_Daily_Analysis_pred_source_from_REST_210613.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM4PUiLgCryH",
        "outputId": "14c7dad4-716c-4760-cf93-65d30239b672"
      },
      "source": [
        "#import the libraries\n",
        "import math\n",
        "import pandas_datareader as web\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "from google.colab import drive\n",
        "#mount gdrive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "#Read data from google spread\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "import requests  # Import the requests library"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfA0kMCZC7gs",
        "outputId": "c85f7837-aad9-40ae-fffc-933162477e05"
      },
      "source": [
        "#Load Model for prediction\n",
        "\n",
        "#model1 = tf.keras.models.load_model('/content/gdrive/MyDrive/saved_model/model_210609c')\n",
        "model1 = tf.keras.models.load_model('/content/gdrive/MyDrive/saved_model/model_210610e')\n",
        "model1.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 500)               1006000   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               50100     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,056,201\n",
            "Trainable params: 1,056,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBvf91b2F2tk"
      },
      "source": [
        "#Get the input data from google spreadsheet 'Input Spreadsheet for Pre'\n",
        "#wb = gc.open_by_key('1WsoN1hkwTGPShVaY2lJVaPb8XKgnp3FwxrxpZclFWKk')\n",
        "\n",
        "#Get the input data from google spreadsheet 'mmyy - Analysis'\n",
        "wb = gc.open_by_key('1XNGejQ8-64jyUReMwDvPcjxZfZzb2_fNPsjww2tX1W4')\n",
        "ws = wb.get_worksheet(0)     \n",
        "tickName = []\n",
        "rows = ws.get_all_values()[1:]\n",
        "rowSize = len(rows)\n",
        "for tick in range(13,rowSize):                   # range = start of tick row - rowSize [zero idx]\n",
        "  if(rows[tick][0] != \"\"):\n",
        "    tickName.append((rows[tick][0][-4:] + \".JK\"))\n",
        "\n",
        "snum = len(tickName)\n",
        "# snum = 3\n",
        "# count = 0\n",
        "for count in range(0,snum):\n",
        "  # ws = wb.get_worksheet(sheetNumber)\n",
        "  # ws = wb.get_worksheet(count)              #parameter = sheet number starting from zero\n",
        "  # tickName = ws.title\n",
        "  print(tickName[count])\n",
        "\n",
        "  # Query URL\n",
        "  url = ('https://query1.finance.yahoo.com/v8/finance/chart/'+ tickName[count] +\n",
        "        '?region=US&lang=en-US&includePrePost=false&interval=30m&useYfid=true&range=5d&corsDomain=finance.yahoo.com')\n",
        "  # print(url)\n",
        "\n",
        "  response = requests.get(url)  # Make a GET request to the URL\n",
        "  payload = response.json()  # Parse `response.text` into JSON\n",
        "\n",
        "  #take data up to yesterday  (strip 14 last records) - when you run the pred next day\n",
        "  # close = payload[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"close\"][0:-14]\n",
        "  # volume = payload[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"volume\"][0:-14]\n",
        "\n",
        "  # no need to strip the data when you run the pred at the same night \n",
        "  close = payload[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"close\"]\n",
        "  volume = payload[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"volume\"]\n",
        "\n",
        "  df1 = pd.DataFrame(close)\n",
        "  df2 = pd.DataFrame(volume)\n",
        "  data1 = df1.fillna(method='ffill')\n",
        "  data2 = df2.fillna(0)\n",
        "  # data1,data2 = newdf.filter(['Close']), newdf.filter(['Volume'])\n",
        "  dataset1, dataset2 = data1.values, data2.values\n",
        "\n",
        "  #scale the data\n",
        "  scaler1 = MinMaxScaler(feature_range=(0,1))\n",
        "  scaled_data1 = scaler1.fit_transform(dataset1)\n",
        "  scaler2 = MinMaxScaler(feature_range=(0,1))\n",
        "  scaled_data2 = scaler2.fit_transform(dataset2)\n",
        "\n",
        "  #data Range for input (check your model)\n",
        "  #dpRange = 56\n",
        "  #dpRange = 48\n",
        "  dpRange = 28\n",
        "\n",
        "  dpSize = len(scaled_data1)\n",
        "  test_data_len = 70\n",
        "  sample_len = 5\n",
        "\n",
        "  #create testing data set\n",
        "  test_data1 = scaled_data1[0:test_data_len,:]\n",
        "  test_data2 = scaled_data2[0:test_data_len,:]\n",
        "\n",
        "  #create the datasets x_test and y_test\n",
        "  trainFeature1 = []\n",
        "  trainFeature2 = []\n",
        "  trainFeature = []\n",
        "  x_test = []\n",
        "  y_train = []\n",
        "\n",
        "  for i in range (dpSize - sample_len, dpSize):\n",
        "  # for i in range (dpRange, dpSize):\n",
        "    trainFeature1.append(test_data1[i-dpRange:i,0])\n",
        "    trainFeature2.append(test_data2[i-dpRange:i,0])\n",
        "    for j in range(0, len(trainFeature1)):\n",
        "      tf = np.array((trainFeature1[j],trainFeature2[j]))\n",
        "\n",
        "    tf = tf.T\n",
        "    x_test.append(tf)\n",
        "    y_train.append(dataset1[i,0])\n",
        "\n",
        "    # if i<= dpRange:\n",
        "    #   print(x_test)\n",
        "    #   print(y_train)\n",
        "\n",
        "  x_test, y_train = np.array(x_test), np.array(y_train)\n",
        "  # x_test.shape\n",
        "\n",
        "  #Calculate preds value using the model\n",
        "  pred1  = model1.predict(x_test)\n",
        "  pred1 = scaler1.inverse_transform(pred1)\n",
        "  predPrice1 = np.round(pred1[:,0])\n",
        "  # print(predPrice1)\n",
        "\n",
        "  predFactor = predPrice1[4] - round(np.average(predPrice1))\n",
        "  priceFactor = y_train[4] - round(np.average(y_train))\n",
        "  #print(predFactor, priceFactor)\n",
        "  #trend calculation\n",
        "\n",
        "  trend = 0\n",
        "\n",
        "  if(priceFactor > 0):\n",
        "    if(predFactor > 0):\n",
        "      trend = priceFactor + predFactor\n",
        "    elif (predFactor == 0):\n",
        "      trend =  priceFactor\n",
        "    else:\n",
        "      trend = (priceFactor + predFactor)/2\n",
        "  elif(priceFactor == 0):\n",
        "    if(predFactor > 0):\n",
        "      trend = predFactor/2\n",
        "    elif (predFactor == 0):\n",
        "      trend =  0\n",
        "    else:\n",
        "      trend = predFactor/2\n",
        "  else:\n",
        "    if(predFactor > 0):\n",
        "      trend = (priceFactor + predFactor)/2\n",
        "    elif (predFactor == 0):\n",
        "      trend =  priceFactor\n",
        "    else:\n",
        "      trend = priceFactor + predFactor\n",
        "  \n",
        "  trend = trend/predPrice1[4]    #make trend as percentage\n",
        "  # print(trend)\n",
        "\n",
        "  #get price & volume info\n",
        "  url1 = ('https://query1.finance.yahoo.com/v7/finance/quote?lang=en-US&region=US&symbols='+ tickName[count] +\n",
        "      '&fields=price%2CregularMarketVolume%2CaverageDailyVolume3Month%2CaverageDailyVolume10Day&corsDomain=finance.yahoo.com')\n",
        "  # print(url)\n",
        "\n",
        "  response1 = requests.get(url1)  # Make a GET request to the URL\n",
        "  payload1 = response1.json()  # Parse `response.text` into JSON\n",
        "  # print(payload1)\n",
        "  mPrice = payload1[\"quoteResponse\"][\"result\"][0][\"regularMarketPrice\"]\n",
        "  mVolume = payload1[\"quoteResponse\"][\"result\"][0][\"regularMarketVolume\"]\n",
        "  avgVol90 = payload1[\"quoteResponse\"][\"result\"][0][\"averageDailyVolume3Month\"]\n",
        "  avgVol10 = payload1[\"quoteResponse\"][\"result\"][0][\"averageDailyVolume10Day\"]\n",
        "\n",
        "  rowIdx = 15  + count  \n",
        "  wRange = \"D\" + str(rowIdx) + \":I\" + str(rowIdx) \n",
        "  cellRange = ws.range(wRange)\n",
        "  ll = 0\n",
        "  for cell in cellRange:\n",
        "    if(ll == 0):\n",
        "      cell.value = str(mPrice)\n",
        "    elif(ll == 1):\n",
        "      cell.value = str(round(predPrice1[4]))\n",
        "    elif(ll == 2):\n",
        "      cell.value = str(trend)\n",
        "    elif(ll == 3):\n",
        "      cell.value = str(mVolume)\n",
        "    elif(ll == 4):\n",
        "      cell.value = str(avgVol90)\n",
        "    else:\n",
        "      cell.value = str(avgVol10)\n",
        "    ll+=1\n",
        "\n",
        "  ws.update_cells(cellRange, \"RAW\")\n",
        "  #write result to gsheet\n",
        "           # write pred result to worksheet staarting at rowIdx, predCol\n",
        "  #update worksheet\n",
        "  # ws.update_cell(rowIdx, 4, str(predPrice1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}